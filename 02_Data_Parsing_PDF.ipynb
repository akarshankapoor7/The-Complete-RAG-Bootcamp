{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f29f784c",
   "metadata": {},
   "source": [
    "### Loading PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6753c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import(\n",
    "    PyPDFLoader,\n",
    "    PyMuPDFLoader,\n",
    "    UnstructuredPDFLoader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b5c122f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyPDFLoader\n",
      "No of pages loaded: 11\n",
      "First document content preview: Attention Is All You Need\n",
      "Ashish Vaswani∗\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeer∗\n",
      "Google Brai...\n",
      "Metadata: {'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': 'data/Attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "#1 PyPDFLoader\n",
    "\"\"\"\n",
    "✅ Simple and lightweight\n",
    "\n",
    "✅ Good for extracting plain text from PDFs\n",
    "\n",
    "⚠️ Sometimes formatting (tables, columns) may not be preserved well\n",
    "\"\"\"\n",
    "\n",
    "print(\"PyPDFLoader\")\n",
    "\n",
    "try:\n",
    "    pypdf_loader = PyPDFLoader(\"data/Attention-is-all-you-need-Paper.pdf\")\n",
    "    pypdf_docs = pypdf_loader.load()\n",
    "    print(f\"No of pages loaded: {len(pypdf_docs)}\")\n",
    "    print(f\"First document content preview: {pypdf_docs[0].page_content[:100]}...\") \n",
    "    print(f\"Metadata: {pypdf_docs[0].metadata}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading PDF: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f33fbae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyMuPDFLoader\n",
      "No of pages loaded: 11\n",
      "First document content preview: Attention Is All You Need\n",
      "Ashish Vaswani∗\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeer∗\n",
      "Google Brai...\n",
      "Metadata: {'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': 'data/Attention-is-all-you-need-Paper.pdf', 'file_path': 'data/Attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "#2 PyMuPDFLoader\n",
    "\"\"\"\n",
    "✅ More powerful than pypdf\n",
    "\n",
    "✅ Preserves text positions and metadata\n",
    "\n",
    "✅ Can handle scanned PDFs (with OCR if you add extra steps)\n",
    "\n",
    "⚠️ Slightly heavier dependency\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"PyMuPDFLoader\")\n",
    "\n",
    "try:\n",
    "    pymupdf_loader = PyMuPDFLoader(\"data/Attention-is-all-you-need-Paper.pdf\")\n",
    "    pymupdf_docs = pymupdf_loader.load()\n",
    "    print(f\"No of pages loaded: {len(pymupdf_docs)}\")\n",
    "    print(f\"First document content preview: {pymupdf_docs[0].page_content[:100]}...\")\n",
    "    print(f\"Metadata: {pymupdf_docs[0].metadata}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading PDF: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a5524",
   "metadata": {},
   "source": [
    "### Handling PDF Challenges ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9393ff",
   "metadata": {},
   "source": [
    "* Text extraction → Fails on scanned/encoded PDFs → Use pdfplumber, PyMuPDF, or OCR (Tesseract).\n",
    "\n",
    "* Layout loss → Broken lines/tables → Use Camelot, Tabula, or layout parsers.\n",
    "\n",
    "* Mixed content → Text + images + tables → Handle separately (OCR + table extractor + text parser).\n",
    "\n",
    "* Large files → Slow/heavy → Process page by page, chunk, or convert to CSV/Parquet.\n",
    "\n",
    "* Scanned PDFs → No text → OCR with preprocessing (deskew, denoise).\n",
    "\n",
    "* Encoding/language → Non-English issues → Use multilingual OCR (Google Vision, PaddleOCR).\n",
    "\n",
    "* Password-protected → Locked PDFs → Unlock with pikepdf or PyPDF2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649d291d",
   "metadata": {},
   "source": [
    "### PDF preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3330f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b57ca94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 11 pages from PDF\n"
     ]
    }
   ],
   "source": [
    "#1. Load the PDF\n",
    "# -----------------------------\n",
    "loader = PyPDFLoader(\"data/Attention-is-all-you-need-Paper.pdf\")  # Change file path\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"✅ Loaded {len(documents)} pages from PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76a47d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created 43 text chunks\n"
     ]
    }
   ],
   "source": [
    "# 2. Split text into chunks\n",
    "# -----------------------------\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,    # characters per chunk\n",
    "    chunk_overlap=200,  # overlap to preserve context\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)\n",
    "print(f\"✅ Created {len(docs)} text chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40081cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned all text chunks\n"
     ]
    }
   ],
   "source": [
    "# 3. Clean text chunks\n",
    "# -----------------------------\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"\\n\", \" \")      # remove line breaks\n",
    "    text = \" \".join(text.split())       # remove extra spaces\n",
    "    return text\n",
    "\n",
    "for doc in docs:\n",
    "    doc.page_content = clean_text(doc.page_content)\n",
    "\n",
    "print(\"✅ Cleaned all text chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c1fed02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample chunk:\n",
      "\n",
      "Attention Is All You Need Ashish Vaswani∗ Google Brain avaswani@google.com Noam Shazeer∗ Google Brain noam@google.com Niki Parmar∗ Google Research nikip@google.com Jakob Uszkoreit∗ Google Research usz@google.com Llion Jones∗ Google Research llion@google.com Aidan N. Gomez∗† University of Toronto aidan@cs.toronto.edu Łukasz Kaiser ∗ Google Brain lukaszkaiser@google.com Illia Polosukhin∗‡ illia.polosukhin@gmail.com Abstract The dominant sequence transduction models are based on complex recurrent o\n"
     ]
    }
   ],
   "source": [
    "# Final Output\n",
    "# -----------------------------\n",
    "print(\"Sample chunk:\\n\")\n",
    "print(docs[0].page_content[:500])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG ext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
